# ğŸ•·ï¸ğŸ·ï¸ bskrape: Web scraping aplicado  
[![en](https://img.shields.io/badge/lang-en-blue.svg)](https://github.com/viccc287/bskrape/blob/main/README.md)

> **Nota**: Â¡Este proyecto naciÃ³ de pura curiosidad y ganas de aprender sobre web scraping!  

> **Nota 2**: El cÃ³digo no es perfecto... pero funciona para mis objetivos iniciales: obtener las ofertas relevantes del sÃºper.

## ğŸ¯ Â¿QuÃ© es?  

Este proyecto es mi espacio para experimentar con web scraping y tiene estas caracterÃ­sticas:  

- **Scraping real**: Por ahora funciona con Bodega Aurrera.  
- **Cazador de ofertas**: bskrape encuentra productos en liquidaciÃ³n (terminados en 01, 02 y 03) y descuentos de mÃ¡s del 40 %.  
- **CÃ³digo de Walmart**: IncluÃ­ cÃ³digo para Walmart, pero estÃ¡ desactivado (los atrapabots me ganaron).  
- **Datos a tu gusto**: Exporta en JSON o CSV, como prefieras.  
- **BÃºsqueda local**: Filtra por cÃ³digo postal.  
- **Logs en vivo**: Para ver quÃ© estÃ¡ pasando en tiempo real.  

> *Â¿Y por quÃ© "bskrape"? "b" de bodega, y "skrape" pues... ya te imaginarÃ¡s.*  

## ğŸŒ CÃ³mo empezar  

Tienes dos opciones:  

### OpciÃ³n 1: Usa el servidor que ya estÃ¡ listo (Â¡la forma rÃ¡pida! ğŸš€)  
Hay un servidor funcionando desde el 22/10/2024. Pero ojo:  
- Puede caerse en cualquier momento (Â¡hey, es un proyecto de aprendizaje!).  
- La primera vez tarda como 10 segundos en despertar (solo dale refresh).  
- Solo conecta tu frontend a la API y listo.  
- **Importante**: El servidor usa un proxy residencial que paguÃ© yo, pero la cuota puede acabarse pronto (Â¡a menos que alguien done ğŸ˜„).  

### OpciÃ³n 2: MÃ³ntalo tÃº mismo (para tener todo el control ğŸ› ï¸)  
Si prefieres correr tu propio servidor:  
1. Clona el repo.  
2. Configura el backend en el puerto 4000.  
3. Conecta tu frontend a `localhost:4000`.  
4. **Importante**: NECESITAS un proxy residencial para evitar bloqueos. Puedes conseguir uno en [Data Impulse](https://app.dataimpulse.com/sign-in).  

## ğŸ” Endpoints de la API  

```markdown
GET  /scrape           # Inicia el scraping  
GET  /get-categories   # Trae las categorÃ­as de la tienda  
GET  /logs             # Mira los logs en vivo  
GET  /ping             # Revisa si el servidor estÃ¡ vivo  
GET  /proxy-status     # Checa cÃ³mo va el proxy  
```

## ğŸš€ Variables de entorno necesarias para el backend
 
   ```bash
   PORT=4000  
   PROXY_URL=tu_url_de_proxy_residencial  # Necesario para que no te detecten... 
   PROXY_USERNAME=tu_usuario  
   PROXY_PASSWORD=tu_contraseÃ±a  
   ```
## ğŸ§ª La parte tÃ©cnica  

- Hecho con Node.js, Express y Puppeteer.  
- Necesitas un proxy residencial para evitar bloqueos (te recomiendo [Data Impulse](https://app.dataimpulse.com/sign-in)).  
- Maneja JSON y CSV.  
- Sistema de logs en tiempo real.  

## âš ï¸ Cosas a tener en cuenta  

- **Sobre el proxy**: El servidor usa un proxy residencial que paguÃ© yo, pero es temporal. Si lo vas a usar en serio, mejor consigue tu propio proxy.  
- **El cÃ³digo de Walmart**: EstÃ¡ desactivado porque detectan bots, pero lo dejÃ© por si quieres aprender con Ã©l.  
- **El servidor**: Como es un proyecto de aprendizaje, puede tener sus momentos de descanso.  

## ğŸ¤ Â¿Quieres contribuir?  

Â¿Tienes ideas, encontraste un bug o quieres mejorarlo? Â¡Manda tu pull request! Es un proyecto para aprender, asÃ­ que aprendamos juntos.  

## ğŸ“œ Licencia  

Licencia MIT - Â¡Ãºsalo para aprender!  

## ğŸ™ Agradecimientos  

Gracias especiales a:  
- La gente de Puppeteer por sus herramientas.  
- La comunidad de Node.js.  
- Todos los que usan esto para aprender sobre web scraping.
- Render por el hosting con Docker.

---

*Â¡Recuerda que esto es para aprender!* ğŸš€  